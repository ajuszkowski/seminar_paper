\documentclass[article]{aaltoseries}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}  % remove spaces before enumerations and lists
\usepackage{url}
%\usepackage{inconsolata}  % for mono font
\usepackage{amssymb}  % for negated \vdash
\usepackage{amsmath}  % for multi-line equations
\begin{document}

%=========================================================

\title{Comparison of Theorem Provers}

\author{Artem Yushkovskiy
\\\textnormal{\texttt{artem.yushkovskiy@aalto.fi}}}

\affiliation{\textbf{Tutor}: Stavros Tripakis}

\maketitle

%==========================================================

\begin{abstract}

The need for formal definition of the very basis of mathematics raised in the last century.
The scale and complexity of mathematics, along with discovered paradoxes, revealed the danger of accumulating errors across theories. Although, according to Gödel's incompleteness theorems, it is not possible to construct a single formal system which will describe all phenomena in the world, being complete and consistent at the same time, that crisis has considerably improved philosophical views on mathematics. 
In addition, it gave rise to rather practical areas of logic, s.a. the theory of automated theorem proving. This is a set of techniques used to verify mathematical statements mechanically using logical reasoning. Moreover, it can be used to solve complex engineering problems as well, for instance, to prove the security properties of a software system or an algorithm.
This paper compares two widespread tools for automated theorem proving, Coq~\cite{tool_Coq} and Isabelle~\cite{tool_Isabelle}, with respect to the power of expressiveness and usability. For this reason, it firstly gives a brief introduction to the bases of formal systems and automated deduction theory, its main problems and challenges.

\vspace{3mm}
\noindent KEYWORDS: logic, formal method, proof theory, automated theorem prover, Coq, Isabelle.
	
\end{abstract}


%============================================================

\section{Introduction}

Nowadays, the search for foundations of mathematics has become one of the key questions in philosophy of mathematics, which eventually have an impact on numerous problems in modern life. Basically, this search has led to the development of \textit{formal approach}, a methodology for manipulating the abstract essences according basic rules in a verifiable way. In other words, it is possible to follow the sequence of such manipulations in order to check the validity of each statement and, as a result, of a system at whole. Moreover, automating such a verification process can significantly increase reliability of formal models and systems based on them.

At present, a large number of tools have been developed to automate this process. Generally, these tools can be divided into two broad classes. 

The first class contains tools pursuing the aim of validating the input statement (\textit{theorem}) with respect to the sequence of inference transitions (user-defined \textit{proof}) according to set of inference rules. Such tools are sometimes called \textit{proof assistants} since they may require some user interaction and may help user to develop new proofs as well. The tools \textit{Isabelle}~\cite{tool_Isabelle}, \textit{Coq}~\cite{tool_Coq}, \textit{PVS}~\cite{tool_Pvs} are well-known examples of such systems, which are commonly used nowadays.

The second class consists of tools that automatically \textit{discover} the formal proof, which can rely either on induction, on meta argument, or on higher-order logic. Such tools are often called \textit{automated theorem provers} so that they apply techniques of automated reasoning to find the proof. The systems \textit{Otter}~\cite{tool_Otter} and \textit{ACL2}~\cite{tool_Acl} are commonly known examples of such tools.

In this paper only systems of the first class were considered, since they can be sufficiently applied in model checking and software verification. 


%------------------------------------------------------------

\subsection{Related work}
A considerably extensive survey on theorem provers has been presented by F.~Wiedijk~\cite{Wie03}, where fifteen 'state-of-the-art' systems for the formalization of mathematics were compared against various properties, in particular size of library with already proved lemmas, strength and expressiveness of underlying logic, size of proofs (the de Bruijn criterion) and level of automation (the Poincaré principle). As the continuation of that work, we propose more deep comparison of two aforementioned theorem provers -- Coq and Isabelle -- with respect to criteria s.a. expressiveness, computation power and usability.

%------------------------------------------------------------

\subsection{Outline}
This paper is organised as follows.
Section~\ref{sec:formal_theory} provides definition, basic properties and theoretical limitations of the formal systems. Section~\ref{sec:auto_reasoning} covers general methods for automated reasoning. Section~\ref{sec:applications} enumerates possible application areas for automated theorem provers. Finally, Section~\ref{sec:comparison} presents target comparison properties and the comparison itself.

%============================================================

\section{Axiomatisation and Formal systems}
\label{sec:formal_theory}

The formal approach appeared in the beginning of previous century when mathematics experienced deep fundamental crisis caused by the need for a formal definition of the very basis. At that time, multiple paradoxes in several fields of mathematics have been discovered. Moreover, the completely new theories appeared just by modification of the set of axioms, e.g., reducing the parallel postulate of Euclidean geometry has lead to completely different non-Euclidian geometries s.a. Lobachevsky's hyperbolic geometry or Riemman's elliptic geometry, that eventually have a large number of applications in both natural sciences and engineering.

\subsection{A logical formal system}
\label{sec:definitions}

% TODO: add citations!

%\texttt{Definition.}
Let the \textit{judgement} be an arbitrary statement. The \textit{formal proof} of the formula $\phi$ is a finite sequence of judgements $ ( \psi_i )_{i=1}^{n} $, where each $\psi_i$ is either an axiom $A_i$, or a formula inferred from the subset $\{ \psi_k \}_{k=1}^{i-1}$ of previously derived formulae according the \textit{rules of inference}. \textit{An axiom} $A_i \in A$ is a judgement evidently claimed to be true. \textit{A logical inference} is a transfer from one judgement (\textit{premise}) to another (\textit{consequence}), which preserve truth. In formal logic, inference is based entirely on the structure of those judgements, thereby, the result formal system represents the abstract model describing part of real world. The proof system described above is called \textit{Hilbert proof system}.
%The set of axioms and rules of logical inference form the \textit{logical system}.

The formulae consists of \textit{propositional variables}, connected with \textit{logical connectives} (or logical operators) according to rules, defined by a formal language. The formulae, which satisfy such rules, are called \textit{well-formed formulae} (wff). Only wff can form judgements in formal system. The propositional variable is an atomic formula which can be either true or false. The logical connective is a symbol in formal language that transforms one wff to another. Typically, the set of logical connectives is $\Omega = \{ \neg, \land, \lor, \rightarrow \}$,

Let $\Phi$ be a set of formulae. Initially, it consists of only \textit{hypotheses}, a priori true formulae, which are claimed to be already proved. The notation $\Phi \vdash \phi$ means that the formula $\phi$ is \textit{provable} from $\Phi$, if there exists a proof that infers $\phi$ from $\Phi$. The formula which is provable without additional premises (i.e. $\emptyset \vdash \phi$) is called \textit{tautology} and denoted as $ \vdash \phi $. The formula is called \textit{contradiction} if $\vdash \neg \phi$. Obviously, all contradictions are equivalent in one formal system, hence they are denoted as $\bot$.

% TODO: \subsection{ ? }

Let $U$ be a set of all possible formulae, let $\Gamma = \ <A, V, \Omega, R>$ be a formal system with set of axioms $A$, set of propositional variables $V$, set of logical operators $\Omega$, and set of propositional variables and set of inference rules $R$. Then $\Gamma$ is called:
\begin{itemize}
	\itemsep0em
	\item \textit{consistent}, if no formula of the system contradicts another: \\
		$\nexists \phi \in \Gamma: \ \Gamma \vdash \phi \land \Gamma \vdash \neg \phi  \ \Leftrightarrow \ \Gamma \nvdash \bot$;
	\item \textit{complete}, if all truth statements can be inferred: \\
		$\forall \phi \in U: \ A \vdash \phi \lor A \vdash \neg \phi$ ;
	\item \textit{independent}, if no axiom can be inferred from another: \\
		$\exists a \in A: \ A \vdash a$.
\end{itemize}

If the propositional variables have no restrictions on their form (i.e. they are 0-arity predicates), such logic is called \textit{propositional logic}. However, if these variables are quantified on some sets, such logic is called \textit{first-order} or \textit{predicate logic}. Commonly, first-order logic has two quantifiers, the universal quantifier '$\forall$' (means "for every"), and the existential quantifier '$\exists$' (means "there exists"). Thereafter, the \textit{second-order logic} extends first-order logic by adding quantifiers over second-order objects -- relations defining the sets of sets. In turn, it can be extended by the \textit{higher-order logic}, which contain quantifiers over the arbitrary nested sets, or \textit{type theory}, which assigns a type for every term in .

% TODO -- finish it
// TODO -- finish it

Although the higher-order logics have stronger semantics than lower-order logics, they have ...

Note, that the first-order logic is \textit{undecidable}, so that there does not exist a decision algorithm which is sound, complete and terminating.

%\begin{itemize}
%\itemsep0em
%	\item what the logical system is (formally: set of axioms, inference rules)
%	\item (?) a brief history of axiomatic approach (Euclid, Hilbert)
%	\item what the truth is: completeness
%	\item intro to set theory (for notation) +Zermelo–Fraenkel set theory (ZFC)
%	\item intro to formal languages
%	\item intro to propositional and 1st ordered logic (introduce notation here. Maybe Higher-Order Logic, Non-classical Logics)
%	\item type systems (+dependent type, where type checking although may be undecidable, but it verifies the correctness of ), Nominal vs. structural type system. \textbf{Curry–Howard correspondence} (the direct relationship between computer programs and mathematical proofs)
%	\item else?
%\end{itemize}

%Let $A, B, C, ...$ be \textit{prepositions}, i.e., statements which preserve facts on real world.  
%Let $\phi$ be a well-formed formula (i.e. a syntactically valid statement) $\Gamma$ be a set of formulas 

% // two words about intuitionism, if needed (in Coq, par exemple)


\subsection{Lambda-calculus}

$\lambda$-\textit{calculus} is a universal computation model invented by Alonzo Church in 1930s as a model for formalising the concept of effective computability. This formalism provides solid theoretical foundation for the family of functional programming languages~\cite{Roj15}. In $\lambda$-calculus, functions are first-order objects, which means functions can be applied as arguments to other functions. According to Church–Turing thesis, $\lambda$-calculus is equivalent to Turing machine in sense that any computable function can be expressed using this formalism.

The central concept in $\lambda$-calculus is an \textit{expression}, which can be defined as a subject for application the rewriting rules~\cite{Bar88}. The basic rewriting rules of $\lambda$-calculus are listed below:

\begin{itemize}
\itemsep0em
	\item Application:
	$f a$ is the call of function $f$ with argument $a$
	
	\item Abstraction:
	$\lambda x.t[x]$ is the function with formal parameter x and body $t[x]$
	
	\item Computation:
	Replace formal parameter by actual argument ($\beta$-\textit{reduction}): \\
	$(\lambda x.t[x]) a \rightarrow_{\beta} t[x:=a]$
\end{itemize}

$\lambda$-calculus described above is called the \textit{type-free} $\lambda$-calculus. By adding the types to expressions, one can construct more strong calculi and prove useful properties for them (e.g., non-termination 
%Combining $\lambda$-expressions with types leads to the typed $\lambda$-calculus, which
%non-termination of typed lambda?


\subsection{Type systems}

A \textit{type} is a collection of elements. In a type system, each element is associated with a type, which restricts set of possible operations with this element. Types can be thought as a structure of objects, that allows to reveal useful properties of the formal system. Type theory therefore serves as an alternative to classic set theory~\cite{Tho91}.
% TODO: remove notation below if not used.
In our notation, the $a =_{\tau} b$ means that $a$ equals $b$ and both of them are of type $\tau$. This notation is used for convenience to encode information about type to equality.

% "the mixture of finite and infinite data types"

\subsubsection{Simple Type Theory}
%In the context of current paper, it is useful to describe 
The type can be defined declaratively, by assigning a label to set of values. Such types are called \textit{simple types}, they can be useful to avoid some paradoxes of set theory, e.g., separating sets of individuals and sets of sets allows to avoid famous Russel's paradox~\cite{Irv95}. Simple type theory can extend $\lambda$-calculus to a Higher-order logic through connection between formulae and expressions of type Boolean~\cite{Paulson90}.

%\subsubsection{Polymorphic Type Theory}
% //not needed
% --
% \subsubsection{System F}
% second-order lambda calculus, is a typed lambda calculus that differs from the simply typed lambda calculus by the introduction of a mechanism of universal quantification over types
% //not needed

\subsubsection{Martin-Löf Type Theory}
also known as \textit{Intuitionistic type theory}, is based on the principles of mathematical constructivism which requires to find a way to "construct" an object in order to prove its existence. Therefore, an important place in intuitionistic type theory is hold by the \textit{inductive types} which were constructed recursively using a basic type (zero) and successor function which defines "next" element. The function that builds new type from another is called \textit{type constructor}.

\subsubsection{Calculus of Constructions}
// TODO
Dependent types
hence type checking may become undecidable.

Inference rules for the calculus of constructions
\begin{enumerate}
	\item ${\displaystyle {{} \over {}\Gamma \vdash P:T}}$
	\item ${\displaystyle {\Gamma \vdash A:K \over {\Gamma ,x:A\vdash x:A}}}$ %{\Gamma, x:A \vdash x : A}}$
	\item ${\displaystyle {\Gamma ,x:A\vdash B:K\qquad \qquad \Gamma ,x:A\vdash N:B \over {\Gamma \vdash (\lambda x:A.N):(\forall x:A.B):K}}}$
	\item ${\displaystyle {\Gamma \vdash M:(\forall x:A.B)\qquad \qquad \Gamma \vdash N:A \over {\Gamma \vdash MN:B[x:=N]}}}$
	\item ${\displaystyle {\Gamma \vdash M:A\qquad \qquad A=_{\beta }B\qquad \qquad B:K \over {\Gamma \vdash M:B}}}$ % \over {\Gamma \vdash M : B}}
\end{enumerate}

%${ {\frac {A,\quad (A\rightarrow B)}{B}}}$ (Modus ponens)


%----------------------------------------------------------

\subsection{Curry-Howard isomorphism}
// TODO
bla-bla, correspondence, isomorphism...
1934–1969

%============================================================

\section{Methods for automated reasoning}
\label{sec:auto_reasoning}

// TODO (Paragraph is still in progress)

techniques in common words (and in introduced previously notation), e.g.: 
\begin{itemize}
\itemsep0em
	\item Clause rewriting
		Simplification - The concept of (conditional) term rewriting is introduced and its realization as the proof method simp is explained. (from http://isabelle.in.tum.de/coursematerial/PSV2009-1/)
		
	\item Resolution
	\item Sequent Deduction
	\item Natural Deduction
	\item The Matrix Connection Method
	\item Term Rewriting (+lambda calculus)
	\item Mathematical Induction
\end{itemize}


% perhaps separate into subsections

%============================================================

\section{Some applications of theorem provers}
\label{sec:applications}

// TODO: think about merging information from this section to introduction.

// TODO (Paragraph is still in progress) 

Describe possible applications of formal methods:
\begin{enumerate}
	\itemsep0em
	\item Interactive theorem proving: construct a formal axiomatic proof of correctness, 
	\item verifying that a mathematical statement is true.
	\item verifying that a circuit description, an algorithm, or a network or security protocol meets its specification:
	\begin{itemize}
		\item program verification (first-order logic), 
		\item distributed and concurrent systems (modal and temporal logics), 
		\item program specification (intuitionistic logic),
		\item Model checking: reduce to a finite state space, and test exhaustively.
		\item hardware verification (higher-order logic), 
		\item logic programming (Horn logic), 
		\item and so on.
	\end{itemize}
\end{enumerate}

%============================================================

\section{Comparison of some theorem provers}
\label{sec:comparison}

We have chosen for our comparison two automated proof assistants, Coq and Isabelle. 
In general, they both work in similar way: given definition of a statement, they can either verify already written proof, or help user to develop such proof in an interactive fashion. They both have rather large libraries that contain considerable amount of already proven theorems. 
Both systems can be used as functional programming languages since they allow to construct new data types and recursive functions.

Although, the key difference between these two systems is that they are based on different logical theories. Isabelle exploits higher order logic along with first-order set theory, while Coq operates with dependent types in higher order type theory, representing an implementation of intuitionistic logic.

%MOCK from "Certified Programming with Dependent Types" by Adam Chlipala.

%Isabelle/HOL and Coq both support coding new proof manipulations in ML in ways that cannot lead to the acceptance of invalid proofs. Additionally, Coq includes a domain-specific language for coding decision procedures in normal Coq source code, with no need to break out into ML.

%A language with dependent types may include references to programs inside of types. For instance, the type of an array might include a program expression giving the size of the array, making it possible to verify absence of out-of-bounds accesses statically. Dependent types can go even further than this, effectively capturing any correctness property in a type. PVS’s dependent types are much more general, but they are squeezed inside the single mechanism of subset types, where a normal type is refined by attaching a predicate over its elements. Each member of the subset type is an element of the base type that satisfies the predicate. 
%*/



%------------------------------------------------------------

\subsection{The Coq theorem prover}
\label{sec:prover_coq}

// TODO (Paragraph is still in progress)

Gérard Huet, Thierry Coquand, Christine Paulin

The Coq is a computer tool for verifying theorem proofs. These theorems may concern usual mathematics, proof theory, or program verification

Coq is a formal proof assistant system. It provides a formal language to write mathematical definitions, executable algorithms and theorems together with an environment for semi-interactive development of machine-checked proofs~\cite{tool_Coq}. Coq uses the Calculus of Construction, a higher-order formalism for constructive proofs in natural deduction style, developed by Thierry Coquand~\cite{Coq86}. 
The Calculus of Construction can be considered as an extension of the Curry–Howard isomorphism. % in a way that the latter associates a term in the simply typed lambda calculus with each natural-deduction proof in intuitionistic propositional logic, when the Calculus of Construction extends this isomorphism to proofs in the full intuitionistic predicate calculus, which includes proofs of quantified statements (which are also called "propositions").

program extraction : Haskell, Scheme and OCaml
(add some core features of Coq ...)

(Coq has been used to formalize ...)

%------------------------------------------------------------

\subsection{The Isabelle theorem prover}
\label{sec:prover_isabelle}

// TODO (Paragraph is still in progress)

// overview good at: https://pdfs.semanticscholar.org/95bf/a1bf0cbf5ae2c2a70daa13d4966143bd96f8.pdf

Main people behind the system: Larry Paulson, Tobias Nipkow, Markus Wenzel

is a theorem prover for various logics, including several first-order logics,
Martin-Loef’s Type Theory, and Zermelo-Fraenkel set theory  (https://pdfs.semanticscholar.org/95bf/a1bf0cbf5ae2c2a70daa13d4966143bd96f8.pdf)

The Isabelle is an interactive theorem prover, which relies on higher-order logic. It allows mathematical formulas to be expressed in a formal language and provides tools for proving those formulas in a logical calculus~\cite{tool_Isabelle}. Isabelle's main proof method is a higher-order version of resolution, based on higher-order unification.

(add some core features of Isabelle ...)

(Isabelle has been used to formalize ...)

%MOCK from wiki:
%/* it is based on a small logical core to ease logical correctness. Isabelle is generic: it provides a meta-logic (a weak type theory), which is used to encode object logics like first-order logic (FOL), higher-order logic (HOL) or Zermelo–Fraenkel set theory (ZFC). Isabelle's main proof method is a higher-order version of resolution, based on higher-order unification. Though interactive, Isabelle also features efficient automatic reasoning tools, such as a term rewriting engine and a tableaux prover, as well as various decision procedures. Isabelle has been used to formalize numerous theorems from mathematics and computer science, like Gödel's completeness theorem, Gödel's theorem about the consistency of the axiom of choice, the prime number theorem, correctness of security protocols, and properties of programming language semantics. The Isabelle theorem prover is free software, released under the revised BSD license.
% */

%------------------------------------------------------------

\subsection{Joint comparison}
\label{sec:joint_comparison}

//TODO: in table:
\begin{itemize}
	\itemsep0em
	\item expressiveness of logic used
	\item time of proving
	\item num of supporting theories
	\item set of techniques to prove automatically
	\item Volume of proof (as text)
	\item num of user interaction steps
	\item usability
	\item etc ...
\end{itemize}

%============================================================

\section{Results}
\label{sec:results}

// TODO (Paragraph is still in progress)
% Pr Tripakis' note: "i think this version can be merged into section 7, perhaps as its last subsection, 7.x"
conclusion of comparison

%============================================================

\section{Future work}
\label{sec:future_work}

// TODO (Paragraph is still in progress)

< in future, we want to apply this survey to software verification >


%============================================================


\bibliographystyle{ieeetr}
\bibliography{cs-seminar}

\end{document}
